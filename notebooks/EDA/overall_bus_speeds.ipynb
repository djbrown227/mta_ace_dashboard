{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "5fd7338c-02cb-4654-b270-1808a07760da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bus Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "f924363d-c59b-4389-b4fd-67f49eac2930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/danielbrown/Desktop/mta-ace-buses/notebooks/EDA'"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "44f33917-6967-4a31-9116-59e518e40b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/danielbrown/Desktop/mta-ace-buses/data/raw')"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Project root = two levels up from notebooks/EDA\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "\n",
    "DATA_RAW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "ddc6c1b8-6f38-4e19-b748-fabcac4338b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/danielbrown/Desktop/mta-ace-buses/data/raw/speeds_monthly_2015.csv'),\n",
       " PosixPath('/Users/danielbrown/Desktop/mta-ace-buses/data/raw/journeyperformance_monthly_2017.csv'),\n",
       " PosixPath('/Users/danielbrown/Desktop/mta-ace-buses/data/raw/bus_lane_geometry.csv'),\n",
       " PosixPath('/Users/danielbrown/Desktop/mta-ace-buses/data/raw/able_ace_start.csv'),\n",
       " PosixPath('/Users/danielbrown/Desktop/mta-ace-buses/data/raw/waitassessment_monthly_2015.csv')]"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(DATA_RAW.iterdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "fcc9d19f-90f3-4aee-a575-fae59c6aeb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>borough</th>\n",
       "      <th>day_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>route_id</th>\n",
       "      <th>period</th>\n",
       "      <th>total_operating_time</th>\n",
       "      <th>total_mileage</th>\n",
       "      <th>average_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>1</td>\n",
       "      <td>LCL/LTD</td>\n",
       "      <td>BX1</td>\n",
       "      <td>Off-Peak</td>\n",
       "      <td>8,710,307</td>\n",
       "      <td>62,940,902.4</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>1</td>\n",
       "      <td>LCL/LTD</td>\n",
       "      <td>BX1</td>\n",
       "      <td>Peak</td>\n",
       "      <td>4,334,312</td>\n",
       "      <td>30,316,503.6</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>2</td>\n",
       "      <td>LCL/LTD</td>\n",
       "      <td>BX1</td>\n",
       "      <td>Off-Peak</td>\n",
       "      <td>2,498,651</td>\n",
       "      <td>18,742,158</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>2</td>\n",
       "      <td>LCL/LTD</td>\n",
       "      <td>BX1</td>\n",
       "      <td>Peak</td>\n",
       "      <td>1,008,139</td>\n",
       "      <td>7,417,580.4</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>1</td>\n",
       "      <td>LCL/LTD</td>\n",
       "      <td>BX10</td>\n",
       "      <td>Off-Peak</td>\n",
       "      <td>5,778,595</td>\n",
       "      <td>52,543,814.4</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month borough  day_type trip_type route_id    period  \\\n",
       "0  2015-01-01   Bronx         1   LCL/LTD      BX1  Off-Peak   \n",
       "1  2015-01-01   Bronx         1   LCL/LTD      BX1      Peak   \n",
       "2  2015-01-01   Bronx         2   LCL/LTD      BX1  Off-Peak   \n",
       "3  2015-01-01   Bronx         2   LCL/LTD      BX1      Peak   \n",
       "4  2015-01-01   Bronx         1   LCL/LTD     BX10  Off-Peak   \n",
       "\n",
       "  total_operating_time total_mileage  average_speed  \n",
       "0            8,710,307  62,940,902.4           7.23  \n",
       "1            4,334,312  30,316,503.6           6.99  \n",
       "2            2,498,651    18,742,158           7.50  \n",
       "3            1,008,139   7,417,580.4           7.36  \n",
       "4            5,778,595  52,543,814.4           9.09  "
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_speeds = pd.read_csv(DATA_RAW / \"speeds_monthly_2015.csv\")\n",
    "df_speeds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "143e3306-f3a6-4410-8ed1-8b8af4e68632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>route_id</th>\n",
       "      <th>total_mileage</th>\n",
       "      <th>total_operating_time</th>\n",
       "      <th>average_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B1</td>\n",
       "      <td>134831203.2</td>\n",
       "      <td>17343453.0</td>\n",
       "      <td>7.774184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B100</td>\n",
       "      <td>65153044.8</td>\n",
       "      <td>6604154.0</td>\n",
       "      <td>9.865464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B103</td>\n",
       "      <td>160917087.6</td>\n",
       "      <td>17885202.0</td>\n",
       "      <td>8.997219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B11</td>\n",
       "      <td>89143142.4</td>\n",
       "      <td>14241253.0</td>\n",
       "      <td>6.259501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B12</td>\n",
       "      <td>91564315.2</td>\n",
       "      <td>15104847.0</td>\n",
       "      <td>6.061916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month route_id  total_mileage  total_operating_time  average_speed\n",
       "0  2015-01-01       B1    134831203.2            17343453.0       7.774184\n",
       "1  2015-01-01     B100     65153044.8             6604154.0       9.865464\n",
       "2  2015-01-01     B103    160917087.6            17885202.0       8.997219\n",
       "3  2015-01-01      B11     89143142.4            14241253.0       6.259501\n",
       "4  2015-01-01      B12     91564315.2            15104847.0       6.061916"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming your dataframe is called df_speeds\n",
    "# Remove commas and convert to numeric\n",
    "df_speeds[\"total_operating_time\"] = pd.to_numeric(\n",
    "    df_speeds[\"total_operating_time\"].str.replace(\",\", \"\"), errors=\"coerce\"\n",
    ")\n",
    "df_speeds[\"total_mileage\"] = pd.to_numeric(\n",
    "    df_speeds[\"total_mileage\"].str.replace(\",\", \"\"), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Group by month and route_id\n",
    "df_grouped = (\n",
    "    df_speeds.groupby([\"month\", \"route_id\"], as_index=False)\n",
    "        .agg({\n",
    "            \"total_mileage\": \"sum\",\n",
    "            \"total_operating_time\": \"sum\"\n",
    "        })\n",
    ")\n",
    "\n",
    "# Calculate average speed per group\n",
    "df_grouped[\"average_speed\"] = df_grouped[\"total_mileage\"] / df_grouped[\"total_operating_time\"]\n",
    "\n",
    "# Reset index (optional, just to be safe)\n",
    "df_grouped.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show result\n",
    "df_grouped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "d65d09b6-a355-4573-aa52-73d56c2aa1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>Program</th>\n",
       "      <th>Implementation Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M15+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>10/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B44+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>10/30/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M14+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>11/21/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B46+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>02/19/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M23+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>08/10/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Route Program Implementation Date\n",
       "0  M15+    ABLE          10/07/2019\n",
       "1  B44+    ABLE          10/30/2019\n",
       "2  M14+    ABLE          11/21/2019\n",
       "3  B46+    ABLE          02/19/2020\n",
       "4  M23+    ABLE          08/10/2020"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ace = pd.read_csv(DATA_RAW / \"able_ace_start.csv\")\n",
    "df_ace.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "de575177-6a45-4339-acf5-9b1bc96a0593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>Program</th>\n",
       "      <th>Implementation Date</th>\n",
       "      <th>Implementation FirstOfMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M15+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>2019-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B44+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M14+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>2019-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B46+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M23+</td>\n",
       "      <td>ABLE</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>2020-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Route Program Implementation Date Implementation FirstOfMonth\n",
       "0  M15+    ABLE          2019-10-07                  2019-10-01\n",
       "1  B44+    ABLE          2019-10-30                  2019-11-01\n",
       "2  M14+    ABLE          2019-11-21                  2019-12-01\n",
       "3  B46+    ABLE          2020-02-19                  2020-03-01\n",
       "4  M23+    ABLE          2020-08-10                  2020-08-01"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df_ace_filtered = df_ace\n",
    "\n",
    "# Convert Implementation Date to datetime\n",
    "df_ace_filtered[\"Implementation Date\"] = pd.to_datetime(\n",
    "    df_ace_filtered[\"Implementation Date\"], format=\"%m/%d/%Y\"\n",
    ")\n",
    "\n",
    "# Function to snap to closest first of month\n",
    "def snap_to_nearest_first_of_month(dt: pd.Timestamp) -> pd.Timestamp:\n",
    "    first_prev = pd.Timestamp(year=dt.year, month=dt.month, day=1)\n",
    "    # first of next month\n",
    "    if dt.month == 12:\n",
    "        first_next = pd.Timestamp(year=dt.year + 1, month=1, day=1)\n",
    "    else:\n",
    "        first_next = pd.Timestamp(year=dt.year, month=dt.month + 1, day=1)\n",
    "    \n",
    "    # return whichever is closer\n",
    "    if (dt - first_prev) <= (first_next - dt):\n",
    "        return first_prev\n",
    "    else:\n",
    "        return first_next\n",
    "\n",
    "# Apply snapping\n",
    "df_ace_filtered[\"Implementation FirstOfMonth\"] = df_ace_filtered[\"Implementation Date\"].apply(snap_to_nearest_first_of_month)\n",
    "\n",
    "# Show result\n",
    "df_ace_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "6743a7dc-afef-4480-b81c-242de80a859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped[\"month\"] = pd.to_datetime(df_grouped[\"month\"])\n",
    "df_ace_filtered[\"Implementation FirstOfMonth\"] = pd.to_datetime(\n",
    "    df_ace_filtered[\"Implementation FirstOfMonth\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "edce8041-85e6-4317-aeda-a2e4e3a8effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ace_filtered = df_ace_filtered.rename(columns={\"Route\": \"route_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "3488bde9-9197-4cc0-ab01-fb830f649586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Program</th>\n",
       "      <th>route_id</th>\n",
       "      <th>ABLE</th>\n",
       "      <th>ACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B25</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B26</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B35</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B41</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Program route_id       ABLE        ACE\n",
       "0            B11        NaT 2025-11-01\n",
       "1            B25 2022-12-01 2024-10-01\n",
       "2            B26 2023-10-01 2024-10-01\n",
       "3            B35        NaT 2024-09-01\n",
       "4            B41        NaT 2024-09-01"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_timeline = (\n",
    "    df_ace_filtered\n",
    "    .pivot_table(\n",
    "        index=\"route_id\",\n",
    "        columns=\"Program\",\n",
    "        values=\"Implementation FirstOfMonth\",\n",
    "        aggfunc=\"min\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "program_timeline.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "697539c8-aab1-4d3b-8fe5-e47465937004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>route_id</th>\n",
       "      <th>total_mileage</th>\n",
       "      <th>total_operating_time</th>\n",
       "      <th>average_speed</th>\n",
       "      <th>ABLE</th>\n",
       "      <th>ACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B11</td>\n",
       "      <td>89143142.4</td>\n",
       "      <td>14241253.0</td>\n",
       "      <td>6.259501</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B25</td>\n",
       "      <td>94309812.0</td>\n",
       "      <td>14408075.0</td>\n",
       "      <td>6.545622</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B26</td>\n",
       "      <td>107962236.0</td>\n",
       "      <td>15654125.0</td>\n",
       "      <td>6.896728</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B35</td>\n",
       "      <td>233463934.8</td>\n",
       "      <td>36833291.0</td>\n",
       "      <td>6.338395</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B41</td>\n",
       "      <td>280574413.2</td>\n",
       "      <td>38472276.0</td>\n",
       "      <td>7.292899</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month route_id  total_mileage  total_operating_time  average_speed  \\\n",
       "0 2015-01-01      B11     89143142.4            14241253.0       6.259501   \n",
       "1 2015-01-01      B25     94309812.0            14408075.0       6.545622   \n",
       "2 2015-01-01      B26    107962236.0            15654125.0       6.896728   \n",
       "3 2015-01-01      B35    233463934.8            36833291.0       6.338395   \n",
       "4 2015-01-01      B41    280574413.2            38472276.0       7.292899   \n",
       "\n",
       "        ABLE        ACE  \n",
       "0        NaT 2025-11-01  \n",
       "1 2022-12-01 2024-10-01  \n",
       "2 2023-10-01 2024-10-01  \n",
       "3        NaT 2024-09-01  \n",
       "4        NaT 2024-09-01  "
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_grouped.merge(\n",
    "    program_timeline,\n",
    "    on=\"route_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf16a6-d2f6-4809-94d4-ab72cdb6bee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "06f4a2c1-09d3-4ec1-b01c-50ab9f24c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>route_id</th>\n",
       "      <th>total_mileage</th>\n",
       "      <th>total_operating_time</th>\n",
       "      <th>y</th>\n",
       "      <th>ABLE</th>\n",
       "      <th>ACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B11</td>\n",
       "      <td>8.914314e+07</td>\n",
       "      <td>1.424125e+07</td>\n",
       "      <td>6.259501</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B25</td>\n",
       "      <td>9.430981e+07</td>\n",
       "      <td>1.440808e+07</td>\n",
       "      <td>6.545622</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B26</td>\n",
       "      <td>1.079622e+08</td>\n",
       "      <td>1.565412e+07</td>\n",
       "      <td>6.896728</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B35</td>\n",
       "      <td>2.334639e+08</td>\n",
       "      <td>3.683329e+07</td>\n",
       "      <td>6.338395</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>B41</td>\n",
       "      <td>2.805744e+08</td>\n",
       "      <td>3.847228e+07</td>\n",
       "      <td>7.292899</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>Q58</td>\n",
       "      <td>6.563016e+04</td>\n",
       "      <td>8.918476e+03</td>\n",
       "      <td>7.358899</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>Q6</td>\n",
       "      <td>4.188061e+04</td>\n",
       "      <td>5.416360e+03</td>\n",
       "      <td>7.732243</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>Q69</td>\n",
       "      <td>2.951430e+04</td>\n",
       "      <td>4.029373e+03</td>\n",
       "      <td>7.324786</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>S46</td>\n",
       "      <td>4.255627e+04</td>\n",
       "      <td>3.895808e+03</td>\n",
       "      <td>10.923606</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>S79+</td>\n",
       "      <td>1.012468e+05</td>\n",
       "      <td>7.012793e+03</td>\n",
       "      <td>14.437450</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6703 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds route_id  total_mileage  total_operating_time          y  \\\n",
       "0    2015-01-01      B11   8.914314e+07          1.424125e+07   6.259501   \n",
       "1    2015-01-01      B25   9.430981e+07          1.440808e+07   6.545622   \n",
       "2    2015-01-01      B26   1.079622e+08          1.565412e+07   6.896728   \n",
       "3    2015-01-01      B35   2.334639e+08          3.683329e+07   6.338395   \n",
       "4    2015-01-01      B41   2.805744e+08          3.847228e+07   7.292899   \n",
       "...         ...      ...            ...                   ...        ...   \n",
       "6698 2025-12-01      Q58   6.563016e+04          8.918476e+03   7.358899   \n",
       "6699 2025-12-01       Q6   4.188061e+04          5.416360e+03   7.732243   \n",
       "6700 2025-12-01      Q69   2.951430e+04          4.029373e+03   7.324786   \n",
       "6701 2025-12-01      S46   4.255627e+04          3.895808e+03  10.923606   \n",
       "6702 2025-12-01     S79+   1.012468e+05          7.012793e+03  14.437450   \n",
       "\n",
       "           ABLE        ACE  \n",
       "0           NaT 2025-11-01  \n",
       "1    2022-12-01 2024-10-01  \n",
       "2    2023-10-01 2024-10-01  \n",
       "3           NaT 2024-09-01  \n",
       "4           NaT 2024-09-01  \n",
       "...         ...        ...  \n",
       "6698 2023-07-01 2024-07-01  \n",
       "6699        NaT 2025-09-01  \n",
       "6700        NaT 2024-10-01  \n",
       "6701        NaT 2024-09-01  \n",
       "6702 2022-11-01 2024-09-01  \n",
       "\n",
       "[6703 rows x 7 columns]"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns to Prophet's required schema\n",
    "df = df.rename(columns={\n",
    "    \"month\": \"ds\",\n",
    "    \"average_speed\": \"y\"\n",
    "})\n",
    "\n",
    "# Ensure ds is datetime\n",
    "df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944b83d-731d-4eb2-83f9-1e54876ff848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077972ab-e03f-43a8-845a-1292202fd142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999686e2-63d3-4b7d-b689-15284b321546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293aff9f-319b-490d-97b8-fa80a5d2ef28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e631e3-dc7d-4914-926b-e25a66f87e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "90ef40c8-20ee-44b3-91df-4c07a3a0c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABLE effect: -0.32%\n",
      "ACE incremental effect: 0.43%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>route_id</th>\n",
       "      <th>total_mileage</th>\n",
       "      <th>total_operating_time</th>\n",
       "      <th>y</th>\n",
       "      <th>ABLE</th>\n",
       "      <th>ACE</th>\n",
       "      <th>is_able</th>\n",
       "      <th>is_ace</th>\n",
       "      <th>is_covid</th>\n",
       "      <th>yhat_no_policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>1.106509e+08</td>\n",
       "      <td>1.988410e+07</td>\n",
       "      <td>5.564794</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.566932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>9.992593e+07</td>\n",
       "      <td>1.810596e+07</td>\n",
       "      <td>5.518952</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.505386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>1.091200e+08</td>\n",
       "      <td>1.987321e+07</td>\n",
       "      <td>5.490809</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.553373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>1.086747e+08</td>\n",
       "      <td>1.987723e+07</td>\n",
       "      <td>5.467297</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.467848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>1.103109e+08</td>\n",
       "      <td>2.029015e+07</td>\n",
       "      <td>5.436673</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.326433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>4.488492e+04</td>\n",
       "      <td>7.671380e+03</td>\n",
       "      <td>5.850957</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.752067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>4.620352e+04</td>\n",
       "      <td>7.907328e+03</td>\n",
       "      <td>5.843127</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.742742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>4.920272e+04</td>\n",
       "      <td>8.440022e+03</td>\n",
       "      <td>5.829691</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.801621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>4.595002e+04</td>\n",
       "      <td>7.799657e+03</td>\n",
       "      <td>5.891288</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.832196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>BX19</td>\n",
       "      <td>4.538856e+04</td>\n",
       "      <td>7.675244e+03</td>\n",
       "      <td>5.913631</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.909275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds route_id  total_mileage  total_operating_time         y  \\\n",
       "0   2015-01-01     BX19   1.106509e+08          1.988410e+07  5.564794   \n",
       "1   2015-02-01     BX19   9.992593e+07          1.810596e+07  5.518952   \n",
       "2   2015-03-01     BX19   1.091200e+08          1.987321e+07  5.490809   \n",
       "3   2015-04-01     BX19   1.086747e+08          1.987723e+07  5.467297   \n",
       "4   2015-05-01     BX19   1.103109e+08          2.029015e+07  5.436673   \n",
       "..         ...      ...            ...                   ...       ...   \n",
       "127 2025-08-01     BX19   4.488492e+04          7.671380e+03  5.850957   \n",
       "128 2025-09-01     BX19   4.620352e+04          7.907328e+03  5.843127   \n",
       "129 2025-10-01     BX19   4.920272e+04          8.440022e+03  5.829691   \n",
       "130 2025-11-01     BX19   4.595002e+04          7.799657e+03  5.891288   \n",
       "131 2025-12-01     BX19   4.538856e+04          7.675244e+03  5.913631   \n",
       "\n",
       "          ABLE        ACE  is_able  is_ace  is_covid  yhat_no_policy  \n",
       "0   2022-12-01 2024-07-01        0       0         0        5.566932  \n",
       "1   2022-12-01 2024-07-01        0       0         0        5.505386  \n",
       "2   2022-12-01 2024-07-01        0       0         0        5.553373  \n",
       "3   2022-12-01 2024-07-01        0       0         0        5.467848  \n",
       "4   2022-12-01 2024-07-01        0       0         0        5.326433  \n",
       "..         ...        ...      ...     ...       ...             ...  \n",
       "127 2022-12-01 2024-07-01        1       1         0        5.752067  \n",
       "128 2022-12-01 2024-07-01        1       1         0        5.742742  \n",
       "129 2022-12-01 2024-07-01        1       1         0        5.801621  \n",
       "130 2022-12-01 2024-07-01        1       1         0        5.832196  \n",
       "131 2022-12-01 2024-07-01        1       1         0        5.909275  \n",
       "\n",
       "[132 rows x 11 columns]"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Select a single route\n",
    "# ------------------------------\n",
    "route = \"BX19\"\n",
    "df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: Prepare columns for Prophet\n",
    "# ------------------------------\n",
    "# Prophet expects 'ds' for datetime and 'y' for target\n",
    "# We'll add regressors:\n",
    "# - is_able: 1 if ABLE is active that month\n",
    "# - is_ace: 1 if ACE is active that month\n",
    "# - is_covid: 1 if month is during COVID unusual period (e.g., Mar 2020 - Jun 2021)\n",
    "df_r[\"is_able\"] = (df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])).astype(int)\n",
    "df_r[\"is_ace\"] = (df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])).astype(int)\n",
    "# Example COVID period — adjust if needed\n",
    "df_r[\"is_covid\"] = ((df_r[\"ds\"] >= \"2020-03-01\") & (df_r[\"ds\"] <= \"2020-09-01\")).astype(int)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: Fit Prophet model\n",
    "# ------------------------------\n",
    "# We'll model pre-policy trends, COVID effects, seasonality, and regressors\n",
    "m0 = Prophet(\n",
    "    yearly_seasonality=True,  # bus speeds vary by month\n",
    "    weekly_seasonality=False, # monthly data, weekly not needed\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "# Add regressors\n",
    "m0.add_regressor(\"is_able\")\n",
    "m0.add_regressor(\"is_ace\")\n",
    "m0.add_regressor(\"is_covid\")\n",
    "\n",
    "# Fit model on historical data\n",
    "m0.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\n",
    "\n",
    "# ------------------------------\n",
    "# Step 4: Make predictions WITHOUT policies\n",
    "# ------------------------------\n",
    "# This gives us the counterfactual (what speeds would have been without ABLE or ACE)\n",
    "# Set ABLE and ACE to 0, keep COVID regressor as-is\n",
    "future = df_r[[\"ds\", \"is_covid\"]].copy()\n",
    "future[\"is_able\"] = 0\n",
    "future[\"is_ace\"] = 0\n",
    "\n",
    "# Predict\n",
    "forecast = m0.predict(future)\n",
    "\n",
    "# Merge predictions back into df_r\n",
    "df_r = df_r.merge(\n",
    "    forecast[[\"ds\", \"yhat\"]],\n",
    "    on=\"ds\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df_r.rename(columns={\"yhat\": \"yhat_no_policy\"}, inplace=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 5: Compute effects\n",
    "# ------------------------------\n",
    "# ABLE effect: average speed increase during ABLE months\n",
    "able_mask = df_r[\"is_able\"] == 1\n",
    "ace_mask = df_r[\"is_ace\"] == 1\n",
    "\n",
    "# ABLE effect: % change vs counterfactual\n",
    "able_effect = (\n",
    "    (df_r.loc[able_mask & ~ace_mask, \"y\"].mean() - \n",
    "     df_r.loc[able_mask & ~ace_mask, \"yhat_no_policy\"].mean())\n",
    "    / df_r.loc[able_mask & ~ace_mask, \"yhat_no_policy\"].mean()\n",
    ") * 100\n",
    "\n",
    "# ACE incremental effect: % change vs counterfactual (already with ABLE)\n",
    "ace_effect = (\n",
    "    (df_r.loc[ace_mask, \"y\"].mean() - \n",
    "     df_r.loc[ace_mask, \"yhat_no_policy\"].mean())\n",
    "    / df_r.loc[ace_mask, \"yhat_no_policy\"].mean()\n",
    ") * 100\n",
    "\n",
    "# ------------------------------\n",
    "# Step 6: Check results\n",
    "# ------------------------------\n",
    "print(f\"ABLE effect: {able_effect:.2f}%\")\n",
    "print(f\"ACE incremental effect: {ace_effect:.2f}%\")\n",
    "\n",
    "# Optional: see the dataframe\n",
    "df_r[[\"ds\", \"y\", \"yhat_no_policy\", \"is_able\", \"is_ace\", \"is_covid\"]].head(20)\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d693c48-3b9c-4f05-802e-9986dfb41193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "c2b69f1d-7625-4451-bb69-5efc4edf4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABLE effect: -0.32%\n",
      "ACE incremental effect: 0.43%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>yhat_no_policy</th>\n",
       "      <th>is_able</th>\n",
       "      <th>is_ace</th>\n",
       "      <th>is_covid</th>\n",
       "      <th>ABLE</th>\n",
       "      <th>ACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>5.745058</td>\n",
       "      <td>5.809580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>5.851027</td>\n",
       "      <td>5.886659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6.012720</td>\n",
       "      <td>5.950544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>5.846285</td>\n",
       "      <td>5.887748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>5.748840</td>\n",
       "      <td>5.869724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>5.767972</td>\n",
       "      <td>5.856179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>5.682400</td>\n",
       "      <td>5.742695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>5.670467</td>\n",
       "      <td>5.724494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>5.854461</td>\n",
       "      <td>5.774722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>5.817770</td>\n",
       "      <td>5.760451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>5.666740</td>\n",
       "      <td>5.731506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>5.774770</td>\n",
       "      <td>5.770748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>5.848258</td>\n",
       "      <td>5.809695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>5.878767</td>\n",
       "      <td>5.883212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>5.956485</td>\n",
       "      <td>5.948243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>5.920340</td>\n",
       "      <td>5.885623</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>5.808189</td>\n",
       "      <td>5.932640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>5.826056</td>\n",
       "      <td>5.846041</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>5.673523</td>\n",
       "      <td>5.703586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>5.745711</td>\n",
       "      <td>5.723850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>5.808222</td>\n",
       "      <td>5.797674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>5.772023</td>\n",
       "      <td>5.791319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>5.752625</td>\n",
       "      <td>5.742234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>5.755634</td>\n",
       "      <td>5.762120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>5.800706</td>\n",
       "      <td>5.809769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>5.903147</td>\n",
       "      <td>5.879873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>5.901975</td>\n",
       "      <td>5.946292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>5.827663</td>\n",
       "      <td>5.884398</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>5.793772</td>\n",
       "      <td>5.765091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>5.843238</td>\n",
       "      <td>5.894462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>5.695300</td>\n",
       "      <td>5.843614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>5.777201</td>\n",
       "      <td>5.751471</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>5.768856</td>\n",
       "      <td>5.753474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>5.698790</td>\n",
       "      <td>5.720972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>5.786531</td>\n",
       "      <td>5.730723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5.800919</td>\n",
       "      <td>5.809492</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>5.805422</td>\n",
       "      <td>5.832027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>5.952016</td>\n",
       "      <td>5.912816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>5.993014</td>\n",
       "      <td>5.975797</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>5.920156</td>\n",
       "      <td>5.913390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>5.924083</td>\n",
       "      <td>5.828930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>5.799726</td>\n",
       "      <td>5.887401</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>5.746447</td>\n",
       "      <td>5.804469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>5.805592</td>\n",
       "      <td>5.748785</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>5.856489</td>\n",
       "      <td>5.775057</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>5.850957</td>\n",
       "      <td>5.752067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>5.843127</td>\n",
       "      <td>5.742742</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>5.829691</td>\n",
       "      <td>5.801621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>5.891288</td>\n",
       "      <td>5.832196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>5.913631</td>\n",
       "      <td>5.909275</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y  yhat_no_policy  is_able  is_ace  is_covid  \\\n",
       "82  2021-11-01  5.745058        5.809580        0       0         0   \n",
       "83  2021-12-01  5.851027        5.886659        0       0         0   \n",
       "84  2022-01-01  6.012720        5.950544        0       0         0   \n",
       "85  2022-02-01  5.846285        5.887748        0       0         0   \n",
       "86  2022-03-01  5.748840        5.869724        0       0         0   \n",
       "87  2022-04-01  5.767972        5.856179        0       0         0   \n",
       "88  2022-05-01  5.682400        5.742695        0       0         0   \n",
       "89  2022-06-01  5.670467        5.724494        0       0         0   \n",
       "90  2022-07-01  5.854461        5.774722        0       0         0   \n",
       "91  2022-08-01  5.817770        5.760451        0       0         0   \n",
       "92  2022-09-01  5.666740        5.731506        0       0         0   \n",
       "93  2022-10-01  5.774770        5.770748        0       0         0   \n",
       "94  2022-11-01  5.848258        5.809695        0       0         0   \n",
       "95  2022-12-01  5.878767        5.883212        1       0         0   \n",
       "96  2023-01-01  5.956485        5.948243        1       0         0   \n",
       "97  2023-02-01  5.920340        5.885623        1       0         0   \n",
       "98  2023-03-01  5.808189        5.932640        1       0         0   \n",
       "99  2023-04-01  5.826056        5.846041        1       0         0   \n",
       "100 2023-05-01  5.673523        5.703586        1       0         0   \n",
       "101 2023-06-01  5.745711        5.723850        1       0         0   \n",
       "102 2023-07-01  5.808222        5.797674        1       0         0   \n",
       "103 2023-08-01  5.772023        5.791319        1       0         0   \n",
       "104 2023-09-01  5.752625        5.742234        1       0         0   \n",
       "105 2023-10-01  5.755634        5.762120        1       0         0   \n",
       "106 2023-11-01  5.800706        5.809769        1       0         0   \n",
       "107 2023-12-01  5.903147        5.879873        1       0         0   \n",
       "108 2024-01-01  5.901975        5.946292        1       0         0   \n",
       "109 2024-02-01  5.827663        5.884398        1       0         0   \n",
       "110 2024-03-01  5.793772        5.765091        1       0         0   \n",
       "111 2024-04-01  5.843238        5.894462        1       0         0   \n",
       "112 2024-05-01  5.695300        5.843614        1       0         0   \n",
       "113 2024-06-01  5.777201        5.751471        1       0         0   \n",
       "114 2024-07-01  5.768856        5.753474        1       1         0   \n",
       "115 2024-08-01  5.698790        5.720972        1       1         0   \n",
       "116 2024-09-01  5.786531        5.730723        1       1         0   \n",
       "117 2024-10-01  5.800919        5.809492        1       1         0   \n",
       "118 2024-11-01  5.805422        5.832027        1       1         0   \n",
       "119 2024-12-01  5.952016        5.912816        1       1         0   \n",
       "120 2025-01-01  5.993014        5.975797        1       1         0   \n",
       "121 2025-02-01  5.920156        5.913390        1       1         0   \n",
       "122 2025-03-01  5.924083        5.828930        1       1         0   \n",
       "123 2025-04-01  5.799726        5.887401        1       1         0   \n",
       "124 2025-05-01  5.746447        5.804469        1       1         0   \n",
       "125 2025-06-01  5.805592        5.748785        1       1         0   \n",
       "126 2025-07-01  5.856489        5.775057        1       1         0   \n",
       "127 2025-08-01  5.850957        5.752067        1       1         0   \n",
       "128 2025-09-01  5.843127        5.742742        1       1         0   \n",
       "129 2025-10-01  5.829691        5.801621        1       1         0   \n",
       "130 2025-11-01  5.891288        5.832196        1       1         0   \n",
       "131 2025-12-01  5.913631        5.909275        1       1         0   \n",
       "\n",
       "          ABLE        ACE  \n",
       "82  2022-12-01 2024-07-01  \n",
       "83  2022-12-01 2024-07-01  \n",
       "84  2022-12-01 2024-07-01  \n",
       "85  2022-12-01 2024-07-01  \n",
       "86  2022-12-01 2024-07-01  \n",
       "87  2022-12-01 2024-07-01  \n",
       "88  2022-12-01 2024-07-01  \n",
       "89  2022-12-01 2024-07-01  \n",
       "90  2022-12-01 2024-07-01  \n",
       "91  2022-12-01 2024-07-01  \n",
       "92  2022-12-01 2024-07-01  \n",
       "93  2022-12-01 2024-07-01  \n",
       "94  2022-12-01 2024-07-01  \n",
       "95  2022-12-01 2024-07-01  \n",
       "96  2022-12-01 2024-07-01  \n",
       "97  2022-12-01 2024-07-01  \n",
       "98  2022-12-01 2024-07-01  \n",
       "99  2022-12-01 2024-07-01  \n",
       "100 2022-12-01 2024-07-01  \n",
       "101 2022-12-01 2024-07-01  \n",
       "102 2022-12-01 2024-07-01  \n",
       "103 2022-12-01 2024-07-01  \n",
       "104 2022-12-01 2024-07-01  \n",
       "105 2022-12-01 2024-07-01  \n",
       "106 2022-12-01 2024-07-01  \n",
       "107 2022-12-01 2024-07-01  \n",
       "108 2022-12-01 2024-07-01  \n",
       "109 2022-12-01 2024-07-01  \n",
       "110 2022-12-01 2024-07-01  \n",
       "111 2022-12-01 2024-07-01  \n",
       "112 2022-12-01 2024-07-01  \n",
       "113 2022-12-01 2024-07-01  \n",
       "114 2022-12-01 2024-07-01  \n",
       "115 2022-12-01 2024-07-01  \n",
       "116 2022-12-01 2024-07-01  \n",
       "117 2022-12-01 2024-07-01  \n",
       "118 2022-12-01 2024-07-01  \n",
       "119 2022-12-01 2024-07-01  \n",
       "120 2022-12-01 2024-07-01  \n",
       "121 2022-12-01 2024-07-01  \n",
       "122 2022-12-01 2024-07-01  \n",
       "123 2022-12-01 2024-07-01  \n",
       "124 2022-12-01 2024-07-01  \n",
       "125 2022-12-01 2024-07-01  \n",
       "126 2022-12-01 2024-07-01  \n",
       "127 2022-12-01 2024-07-01  \n",
       "128 2022-12-01 2024-07-01  \n",
       "129 2022-12-01 2024-07-01  \n",
       "130 2022-12-01 2024-07-01  \n",
       "131 2022-12-01 2024-07-01  "
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Select a single route\n",
    "# ------------------------------\n",
    "route = \"BX19\"\n",
    "df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: Prepare columns for Prophet\n",
    "# ------------------------------\n",
    "# Prophet requires 'ds' for datetime and 'y' for target variable\n",
    "# We'll create binary regressors:\n",
    "# - is_able: 1 if ABLE is active that month\n",
    "# - is_ace: 1 if ACE is active that month\n",
    "# - is_covid: 1 if month is during unusual COVID period (bus speeds anomalous)\n",
    "df_r[\"is_able\"] = (df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])).astype(int)\n",
    "df_r[\"is_ace\"] = (df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])).astype(int)\n",
    "df_r[\"is_covid\"] = ((df_r[\"ds\"] >= \"2020-03-01\") & (df_r[\"ds\"] <= \"2020-09-01\")).astype(int)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: Fit Prophet model\n",
    "# ------------------------------\n",
    "# Model the trend in bus speeds with seasonality, COVID, ABLE, ACE\n",
    "m0 = Prophet(\n",
    "    yearly_seasonality=True,  # capture seasonal monthly patterns\n",
    "    weekly_seasonality=False, # monthly data, weekly not needed\n",
    "    daily_seasonality=False\n",
    ")\n",
    "# Add the policy regressors and COVID regressor\n",
    "m0.add_regressor(\"is_able\")\n",
    "m0.add_regressor(\"is_ace\")\n",
    "m0.add_regressor(\"is_covid\")\n",
    "\n",
    "# Fit the model to the historical data\n",
    "m0.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\n",
    "\n",
    "# ------------------------------\n",
    "# Step 4: Create counterfactual predictions\n",
    "# ------------------------------\n",
    "# Counterfactual = what would have happened without ABLE or ACE\n",
    "future = df_r[[\"ds\", \"is_covid\"]].copy()  # keep COVID effect as-is\n",
    "future[\"is_able\"] = 0                       # turn off ABLE\n",
    "future[\"is_ace\"] = 0                        # turn off ACE\n",
    "\n",
    "# Generate predictions\n",
    "forecast = m0.predict(future)\n",
    "\n",
    "# Merge back into df_r\n",
    "df_r = df_r.merge(forecast[[\"ds\", \"yhat\"]], on=\"ds\", how=\"left\")\n",
    "df_r.rename(columns={\"yhat\": \"yhat_no_policy\"}, inplace=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 5: Define masks for effects\n",
    "# ------------------------------\n",
    "# Mask for months post-ABLE but before ACE (ABLE effect only)\n",
    "able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\n",
    "\n",
    "# Mask for months post-ACE (ACE incremental effect)\n",
    "ace_mask = df_r[\"is_ace\"] == 1\n",
    "\n",
    "# ------------------------------\n",
    "# Step 6: Compute effects\n",
    "# ------------------------------\n",
    "# ABLE effect: compare post-ABLE months to pre-ABLE baseline (counterfactual)\n",
    "able_effect = (\n",
    "    (df_r.loc[able_only_mask, \"y\"].mean() - df_r.loc[able_only_mask, \"yhat_no_policy\"].mean())\n",
    "    / df_r.loc[able_only_mask, \"yhat_no_policy\"].mean()\n",
    ") * 100\n",
    "\n",
    "# ACE incremental effect: compare post-ACE months to baseline including ABLE (if existed)\n",
    "ace_effect = (\n",
    "    (df_r.loc[ace_mask, \"y\"].mean() - df_r.loc[ace_mask, \"yhat_no_policy\"].mean())\n",
    "    / df_r.loc[ace_mask, \"yhat_no_policy\"].mean()\n",
    ") * 100\n",
    "\n",
    "# ------------------------------\n",
    "# Step 7: Check results\n",
    "# ------------------------------\n",
    "print(f\"ABLE effect: {able_effect:.2f}%\")   # % change due to ABLE\n",
    "print(f\"ACE incremental effect: {ace_effect:.2f}%\")  # % change due to ACE on top of ABLE\n",
    "\n",
    "# Optional: Inspect the dataframe\n",
    "df_r[[\"ds\", \"y\", \"yhat_no_policy\", \"is_able\", \"is_ace\", \"is_covid\", \"ABLE\", \"ACE\"]].tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e0610-84fb-4d8c-adbe-aeee7d1f5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "8af9428a-d2c6-482c-b3af-05ef5530c4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom prophet import Prophet\\nimport pandas as pd\\nimport numpy as np\\n\\n# ------------------------------\\n# Step 0: Prepare an empty list to collect results\\n# ------------------------------\\nresults = []\\n\\n# ------------------------------\\n# Step 1: Loop over all routes\\n# ------------------------------\\nfor route in df[\"route_id\"].unique():\\n    # Select data for this route\\n    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\\n\\n    # Skip route if it has too few data points\\n    if len(df_r) < 12:\\n        continue\\n\\n    # ------------------------------\\n    # Step 2: Prepare regressors\\n    # ------------------------------\\n    df_r[\"is_able\"] = (df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])).astype(int)\\n    df_r[\"is_ace\"] = (df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])).astype(int)\\n    df_r[\"is_covid\"] = ((df_r[\"ds\"] >= \"2020-03-01\") & (df_r[\"ds\"] <= \"2020-09-01\")).astype(int)\\n\\n    # ------------------------------\\n    # Step 3: Fit Prophet model\\n    # ------------------------------\\n    try:\\n        m0 = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\\n        m0.add_regressor(\"is_able\")\\n        m0.add_regressor(\"is_ace\")\\n        m0.add_regressor(\"is_covid\")\\n        m0.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\\n    except Exception as e:\\n        print(f\"Skipping route {route} due to error in Prophet: {e}\")\\n        continue\\n\\n    # ------------------------------\\n    # Step 4: Predict counterfactual (no ABLE or ACE)\\n    # ------------------------------\\n    future = df_r[[\"ds\", \"is_covid\"]].copy()\\n    future[\"is_able\"] = 0\\n    future[\"is_ace\"] = 0\\n    forecast = m0.predict(future)\\n    df_r = df_r.merge(forecast[[\"ds\", \"yhat\"]], on=\"ds\", how=\"left\")\\n    df_r.rename(columns={\"yhat\": \"yhat_no_policy\"}, inplace=True)\\n\\n    # ------------------------------\\n    # Step 5: Compute effects\\n    # ------------------------------\\n    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\\n    ace_mask = df_r[\"is_ace\"] == 1\\n\\n    able_effect = (\\n        (df_r.loc[able_only_mask, \"y\"].mean() - df_r.loc[able_only_mask, \"yhat_no_policy\"].mean())\\n        / df_r.loc[able_only_mask, \"yhat_no_policy\"].mean()\\n    ) * 100 if able_only_mask.any() else np.nan  # NaN if no ABLE\\n\\n    ace_effect = (\\n        (df_r.loc[ace_mask, \"y\"].mean() - df_r.loc[ace_mask, \"yhat_no_policy\"].mean())\\n        / df_r.loc[ace_mask, \"yhat_no_policy\"].mean()\\n    ) * 100 if ace_mask.any() else np.nan  # NaN if no ACE\\n\\n    # ------------------------------\\n    # Step 6: Store results\\n    # ------------------------------\\n    results.append({\\n        \"route_id\": route,\\n        \"able_effect_pct\": able_effect,\\n        \"ace_incremental_effect_pct\": ace_effect\\n    })\\n\\n# ------------------------------\\n# Step 7: Convert results to dataframe\\n# ------------------------------\\n\\n\\ndf_effects = pd.DataFrame(results)\\ndf_effects\\n'"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Step 0: Prepare an empty list to collect results\n",
    "# ------------------------------\n",
    "results = []\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Loop over all routes\n",
    "# ------------------------------\n",
    "for route in df[\"route_id\"].unique():\n",
    "    # Select data for this route\n",
    "    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\n",
    "\n",
    "    # Skip route if it has too few data points\n",
    "    if len(df_r) < 12:\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 2: Prepare regressors\n",
    "    # ------------------------------\n",
    "    df_r[\"is_able\"] = (df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])).astype(int)\n",
    "    df_r[\"is_ace\"] = (df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])).astype(int)\n",
    "    df_r[\"is_covid\"] = ((df_r[\"ds\"] >= \"2020-03-01\") & (df_r[\"ds\"] <= \"2020-09-01\")).astype(int)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 3: Fit Prophet model\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        m0 = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "        m0.add_regressor(\"is_able\")\n",
    "        m0.add_regressor(\"is_ace\")\n",
    "        m0.add_regressor(\"is_covid\")\n",
    "        m0.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping route {route} due to error in Prophet: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 4: Predict counterfactual (no ABLE or ACE)\n",
    "    # ------------------------------\n",
    "    future = df_r[[\"ds\", \"is_covid\"]].copy()\n",
    "    future[\"is_able\"] = 0\n",
    "    future[\"is_ace\"] = 0\n",
    "    forecast = m0.predict(future)\n",
    "    df_r = df_r.merge(forecast[[\"ds\", \"yhat\"]], on=\"ds\", how=\"left\")\n",
    "    df_r.rename(columns={\"yhat\": \"yhat_no_policy\"}, inplace=True)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 5: Compute effects\n",
    "    # ------------------------------\n",
    "    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\n",
    "    ace_mask = df_r[\"is_ace\"] == 1\n",
    "\n",
    "    able_effect = (\n",
    "        (df_r.loc[able_only_mask, \"y\"].mean() - df_r.loc[able_only_mask, \"yhat_no_policy\"].mean())\n",
    "        / df_r.loc[able_only_mask, \"yhat_no_policy\"].mean()\n",
    "    ) * 100 if able_only_mask.any() else np.nan  # NaN if no ABLE\n",
    "\n",
    "    ace_effect = (\n",
    "        (df_r.loc[ace_mask, \"y\"].mean() - df_r.loc[ace_mask, \"yhat_no_policy\"].mean())\n",
    "        / df_r.loc[ace_mask, \"yhat_no_policy\"].mean()\n",
    "    ) * 100 if ace_mask.any() else np.nan  # NaN if no ACE\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 6: Store results\n",
    "    # ------------------------------\n",
    "    results.append({\n",
    "        \"route_id\": route,\n",
    "        \"able_effect_pct\": able_effect,\n",
    "        \"ace_incremental_effect_pct\": ace_effect\n",
    "    })\n",
    "\n",
    "# ------------------------------\n",
    "# Step 7: Convert results to dataframe\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "df_effects = pd.DataFrame(results)\n",
    "df_effects\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b889c-0053-42ec-a9c3-5bc688732d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "456b5932-2642-401e-8764-2db0809a0441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#This is graph 1. It will be a histogram for total_effect_pct\\ndf_effects[\"total_effect_pct\"] = (\\n    (1 + df_effects[\"able_effect_pct\"].fillna(0) / 100)\\n    * (1 + df_effects[\"ace_incremental_effect_pct\"].fillna(0) / 100)\\n    - 1\\n) * 100\\n\\ndf_effects\\n'"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This is graph 1. It will be a histogram for total_effect_pct\n",
    "df_effects[\"total_effect_pct\"] = (\n",
    "    (1 + df_effects[\"able_effect_pct\"].fillna(0) / 100)\n",
    "    * (1 + df_effects[\"ace_incremental_effect_pct\"].fillna(0) / 100)\n",
    "    - 1\n",
    ") * 100\n",
    "\n",
    "df_effects\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4a794-d9a7-43c9-a380-eeb5da2c00dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "b22d98c7-edb7-4770-bdf5-39029a1ad5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# Data\\nx = df_effects[\"total_effect_pct\"].dropna()\\n\\n# Choose bin width (policy-friendly)\\nBIN_WIDTH = 2  # percent points\\n\\n# Compute bounds\\nmin_val = np.floor(x.min() / BIN_WIDTH) * BIN_WIDTH\\nmax_val = np.ceil(x.max() / BIN_WIDTH) * BIN_WIDTH\\n\\n# Build bins that include zero explicitly\\nnegative_bins = np.arange(min_val, 0, BIN_WIDTH)\\npositive_bins = np.arange(0, max_val + BIN_WIDTH, BIN_WIDTH)\\n\\nbins = np.concatenate([negative_bins, positive_bins])\\n\\nplt.figure(figsize=(8, 4))\\n\\nsns.histplot(\\n    x,\\n    bins=bins\\n)\\n\\nplt.axvline(0, linestyle=\"--\", linewidth=1)\\nplt.xlabel(\"Total Effect (% change)\")\\nplt.ylabel(\"Number of routes\")\\nplt.title(\"Distribution of Total Program Effects\")\\n\\nplt.tight_layout()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "x = df_effects[\"total_effect_pct\"].dropna()\n",
    "\n",
    "# Choose bin width (policy-friendly)\n",
    "BIN_WIDTH = 2  # percent points\n",
    "\n",
    "# Compute bounds\n",
    "min_val = np.floor(x.min() / BIN_WIDTH) * BIN_WIDTH\n",
    "max_val = np.ceil(x.max() / BIN_WIDTH) * BIN_WIDTH\n",
    "\n",
    "# Build bins that include zero explicitly\n",
    "negative_bins = np.arange(min_val, 0, BIN_WIDTH)\n",
    "positive_bins = np.arange(0, max_val + BIN_WIDTH, BIN_WIDTH)\n",
    "\n",
    "bins = np.concatenate([negative_bins, positive_bins])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "sns.histplot(\n",
    "    x,\n",
    "    bins=bins\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Total Effect (% change)\")\n",
    "plt.ylabel(\"Number of routes\")\n",
    "plt.title(\"Distribution of Total Program Effects\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "3b1342b4-4291-4dd3-8d52-b7df0f96273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ------------------------------\\n# Summary statistics for effects\\n# ------------------------------\\n\\nsummary = {}\\n\\nfor col in [\"able_effect_pct\", \"ace_incremental_effect_pct\",\"total_effect_pct\"]:\\n    series = df_effects[col].dropna()\\n\\n    summary[col] = {\\n        \"mean\": series.mean(),\\n        \"median\": series.median(),\\n        \"q25\": series.quantile(0.25),\\n        \"q75\": series.quantile(0.75),\\n        \"iqr\": series.quantile(0.75) - series.quantile(0.25),\\n        \"n_routes\": series.shape[0]\\n    }\\n\\nsummary_df = pd.DataFrame(summary).T\\nsummary_df\\n'"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# ------------------------------\n",
    "# Summary statistics for effects\n",
    "# ------------------------------\n",
    "\n",
    "summary = {}\n",
    "\n",
    "for col in [\"able_effect_pct\", \"ace_incremental_effect_pct\",\"total_effect_pct\"]:\n",
    "    series = df_effects[col].dropna()\n",
    "\n",
    "    summary[col] = {\n",
    "        \"mean\": series.mean(),\n",
    "        \"median\": series.median(),\n",
    "        \"q25\": series.quantile(0.25),\n",
    "        \"q75\": series.quantile(0.75),\n",
    "        \"iqr\": series.quantile(0.75) - series.quantile(0.25),\n",
    "        \"n_routes\": series.shape[0]\n",
    "    }\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T\n",
    "summary_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "17de24ad-bbad-4e2e-b53b-f3cfd8ffaad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport numpy as np\\n\\ndef robust_summary(series):\\n    s = series.dropna()\\n    return pd.Series({\\n        \"n_routes\": s.shape[0],\\n        \"mean\": s.mean(),\\n        \"median\": s.median(),\\n        \"trimmed_mean_10pct\": s.sort_values().iloc[int(0.1*len(s)) : int(0.9*len(s))].mean()\\n            if len(s) >= 10 else np.nan,\\n        \"std_dev\": s.std(),\\n        \"mad\": (s - s.median()).abs().median(),\\n        \"min\": s.min(),\\n        \"q25\": s.quantile(0.25),\\n        \"q75\": s.quantile(0.75),\\n        \"max\": s.max(),\\n        \"pct_positive\": (s > 0).mean() * 100,\\n        \"pct_negative\": (s < 0).mean() * 100,\\n        \"pct_near_zero\": (s.abs() < 0.5).mean() * 100\\n    })\\n'"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def robust_summary(series):\n",
    "    s = series.dropna()\n",
    "    return pd.Series({\n",
    "        \"n_routes\": s.shape[0],\n",
    "        \"mean\": s.mean(),\n",
    "        \"median\": s.median(),\n",
    "        \"trimmed_mean_10pct\": s.sort_values().iloc[int(0.1*len(s)) : int(0.9*len(s))].mean()\n",
    "            if len(s) >= 10 else np.nan,\n",
    "        \"std_dev\": s.std(),\n",
    "        \"mad\": (s - s.median()).abs().median(),\n",
    "        \"min\": s.min(),\n",
    "        \"q25\": s.quantile(0.25),\n",
    "        \"q75\": s.quantile(0.75),\n",
    "        \"max\": s.max(),\n",
    "        \"pct_positive\": (s > 0).mean() * 100,\n",
    "        \"pct_negative\": (s < 0).mean() * 100,\n",
    "        \"pct_near_zero\": (s.abs() < 0.5).mean() * 100\n",
    "    })\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "37048d77-264c-42f1-9c48-39ffad44c1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsummary_stats = pd.concat(\\n    {\\n        \"ABLE effect (%)\": robust_summary(df_effects[\"able_effect_pct\"]),\\n        \"ACE incremental effect (%)\": robust_summary(df_effects[\"ace_incremental_effect_pct\"]),\\n        \"TOTAL compounded effect (%)\": robust_summary(df_effects[\"total_effect_pct\"])\\n    },\\n    axis=1\\n)\\n\\nsummary_stats\\n'"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "summary_stats = pd.concat(\n",
    "    {\n",
    "        \"ABLE effect (%)\": robust_summary(df_effects[\"able_effect_pct\"]),\n",
    "        \"ACE incremental effect (%)\": robust_summary(df_effects[\"ace_incremental_effect_pct\"]),\n",
    "        \"TOTAL compounded effect (%)\": robust_summary(df_effects[\"total_effect_pct\"])\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "summary_stats\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "3cc56d08-b924-4250-b449-083db4c27622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_effects[\"is_sbs\"] = df_effects[\"route_id\"].str.contains(\"\\\\+\")\\n\\ngrouped_summary = df_effects.groupby(\"is_sbs\").apply(\\n    lambda g: robust_summary(g[\"total_effect_pct\"])\\n)\\n\\ngrouped_summary\\n'"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_effects[\"is_sbs\"] = df_effects[\"route_id\"].str.contains(\"\\+\")\n",
    "\n",
    "grouped_summary = df_effects.groupby(\"is_sbs\").apply(\n",
    "    lambda g: robust_summary(g[\"total_effect_pct\"])\n",
    ")\n",
    "\n",
    "grouped_summary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "dac8807d-9e09-47b5-98c1-0bc45f545c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:59:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABLE effect (%)</th>\n",
       "      <th>ACE incremental effect (%)</th>\n",
       "      <th>TOTAL compounded effect (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_routes</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.276132</td>\n",
       "      <td>0.933257</td>\n",
       "      <td>1.502802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>-0.114299</td>\n",
       "      <td>0.333738</td>\n",
       "      <td>0.318266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trimmed_mean_10pct</th>\n",
       "      <td>0.514104</td>\n",
       "      <td>0.367011</td>\n",
       "      <td>0.367705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev</th>\n",
       "      <td>4.493084</td>\n",
       "      <td>3.440155</td>\n",
       "      <td>6.390713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mad</th>\n",
       "      <td>1.000983</td>\n",
       "      <td>1.163304</td>\n",
       "      <td>1.111921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.094157</td>\n",
       "      <td>-4.729990</td>\n",
       "      <td>-8.630495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25</th>\n",
       "      <td>-0.581919</td>\n",
       "      <td>-0.444627</td>\n",
       "      <td>-0.669772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75</th>\n",
       "      <td>1.334065</td>\n",
       "      <td>1.630937</td>\n",
       "      <td>1.497042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.478066</td>\n",
       "      <td>17.925703</td>\n",
       "      <td>36.178321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_positive</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>54.716981</td>\n",
       "      <td>56.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_negative</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>45.283019</td>\n",
       "      <td>43.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_near_zero</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>33.962264</td>\n",
       "      <td>30.188679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ABLE effect (%)  ACE incremental effect (%)  \\\n",
       "n_routes                  20.000000                   53.000000   \n",
       "mean                       1.276132                    0.933257   \n",
       "median                    -0.114299                    0.333738   \n",
       "trimmed_mean_10pct         0.514104                    0.367011   \n",
       "std_dev                    4.493084                    3.440155   \n",
       "mad                        1.000983                    1.163304   \n",
       "min                       -4.094157                   -4.729990   \n",
       "q25                       -0.581919                   -0.444627   \n",
       "q75                        1.334065                    1.630937   \n",
       "max                       15.478066                   17.925703   \n",
       "pct_positive              45.000000                   54.716981   \n",
       "pct_negative              55.000000                   45.283019   \n",
       "pct_near_zero             30.000000                   33.962264   \n",
       "\n",
       "                    TOTAL compounded effect (%)  \n",
       "n_routes                              53.000000  \n",
       "mean                                   1.502802  \n",
       "median                                 0.318266  \n",
       "trimmed_mean_10pct                     0.367705  \n",
       "std_dev                                6.390713  \n",
       "mad                                    1.111921  \n",
       "min                                   -8.630495  \n",
       "q25                                   -0.669772  \n",
       "q75                                    1.497042  \n",
       "max                                   36.178321  \n",
       "pct_positive                          56.603774  \n",
       "pct_negative                          43.396226  \n",
       "pct_near_zero                         30.188679  "
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------\n",
    "MIN_OBS = 12\n",
    "\n",
    "COVID_START = \"2020-03-01\"\n",
    "COVID_END   = \"2021-03-01\"   # conservative: include recovery\n",
    "\n",
    "# ------------------------------\n",
    "# Step 0: Prepare results list\n",
    "# ------------------------------\n",
    "results = []\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Loop over routes\n",
    "# ------------------------------\n",
    "for route in df[\"route_id\"].unique():\n",
    "\n",
    "    # Select route data\n",
    "    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 1a: REMOVE COVID PERIOD\n",
    "    # ------------------------------\n",
    "    df_r = df_r[\n",
    "        ~((df_r[\"ds\"] >= COVID_START) & (df_r[\"ds\"] <= COVID_END))\n",
    "    ]\n",
    "\n",
    "    # Skip if too little data remains\n",
    "    if len(df_r) < MIN_OBS:\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 2: Policy indicators\n",
    "    # ------------------------------\n",
    "    df_r[\"is_able\"] = (\n",
    "        df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    df_r[\"is_ace\"] = (\n",
    "        df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 3: Fit Prophet\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        m0 = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            changepoint_prior_scale=0.05  # conservative trend\n",
    "        )\n",
    "\n",
    "        m0.add_regressor(\"is_able\")\n",
    "        m0.add_regressor(\"is_ace\")\n",
    "\n",
    "        m0.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping route {route}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 4: Counterfactual (no ABLE / ACE)\n",
    "    # ------------------------------\n",
    "    future = df_r[[\"ds\"]].copy()\n",
    "    future[\"is_able\"] = 0\n",
    "    future[\"is_ace\"] = 0\n",
    "\n",
    "    forecast = m0.predict(future)\n",
    "\n",
    "    df_r = df_r.merge(\n",
    "        forecast[[\"ds\", \"yhat\"]],\n",
    "        on=\"ds\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df_r.rename(columns={\"yhat\": \"yhat_no_policy\"}, inplace=True)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 5: Effect masks\n",
    "    # ------------------------------\n",
    "    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\n",
    "    ace_mask = (df_r[\"is_ace\"] == 1)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 6: Compute effects\n",
    "    # ------------------------------\n",
    "    able_effect = (\n",
    "        (df_r.loc[able_only_mask, \"y\"].mean()\n",
    "         - df_r.loc[able_only_mask, \"yhat_no_policy\"].mean())\n",
    "        / df_r.loc[able_only_mask, \"yhat_no_policy\"].mean()\n",
    "    ) * 100 if able_only_mask.any() else np.nan\n",
    "\n",
    "    ace_effect = (\n",
    "        (df_r.loc[ace_mask, \"y\"].mean()\n",
    "         - df_r.loc[ace_mask, \"yhat_no_policy\"].mean())\n",
    "        / df_r.loc[ace_mask, \"yhat_no_policy\"].mean()\n",
    "    ) * 100 if ace_mask.any() else np.nan\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 7: Store results\n",
    "    # ------------------------------\n",
    "    results.append({\n",
    "        \"route_id\": route,\n",
    "        \"able_effect_pct\": able_effect,\n",
    "        \"ace_incremental_effect_pct\": ace_effect\n",
    "    })\n",
    "\n",
    "# ------------------------------\n",
    "# Step 8: Final dataframe\n",
    "# ------------------------------\n",
    "df_effects = pd.DataFrame(results)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 9: Total compounded effect\n",
    "# ------------------------------\n",
    "df_effects[\"total_effect_pct\"] = (\n",
    "    (1 + df_effects[\"able_effect_pct\"].fillna(0) / 100)\n",
    "    * (1 + df_effects[\"ace_incremental_effect_pct\"].fillna(0) / 100)\n",
    "    - 1\n",
    ") * 100\n",
    "\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_effects.to_csv(\n",
    "    DATA_PROCESSED / \"speed_overall.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "df_effects\n",
    "\n",
    "summary_stats = pd.concat(\n",
    "    {\n",
    "        \"ABLE effect (%)\": robust_summary(df_effects[\"able_effect_pct\"]),\n",
    "        \"ACE incremental effect (%)\": robust_summary(df_effects[\"ace_incremental_effect_pct\"]),\n",
    "        \"TOTAL compounded effect (%)\": robust_summary(df_effects[\"total_effect_pct\"])\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "e8d7fe0b-bcc8-44a8-a8bf-2ae43e4250df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ speedOverall.ts written\n"
     ]
    }
   ],
   "source": [
    "# Converting to TypeScript\n",
    "df = df_effects.copy()\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"route_id\": \"routeId\",\n",
    "    \"able_effect_pct\": \"ableEffectPct\",\n",
    "    \"ace_incremental_effect_pct\": \"aceIncrementalEffectPct\",\n",
    "    \"total_effect_pct\": \"totalEffectPct\"\n",
    "})\n",
    "\n",
    "# Convert NaN → None\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "def to_ts_value(v):\n",
    "    if v is None:\n",
    "        return \"null\"\n",
    "    if isinstance(v, float) and math.isnan(v):\n",
    "        return \"null\"\n",
    "    return round(float(v), 4)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    rows.append(\n",
    "        f\"\"\"  {{\n",
    "    routeId: \"{r.routeId}\",\n",
    "    ableEffectPct: {to_ts_value(r.ableEffectPct)},\n",
    "    aceIncrementalEffectPct: {to_ts_value(r.aceIncrementalEffectPct)},\n",
    "    totalEffectPct: {to_ts_value(r.totalEffectPct)}\n",
    "  }}\"\"\"\n",
    "    )\n",
    "\n",
    "# 🔧 FIX: join rows *outside* the f-string\n",
    "rows_joined = \",\\n\".join(rows)\n",
    "\n",
    "ts = f\"\"\"\n",
    "export type SpeedPeakRow = {{\n",
    "  routeId: string;\n",
    "  ableEffectPct: number | null;\n",
    "  aceIncrementalEffectPct: number | null;\n",
    "  totalEffectPct: number;\n",
    "}};\n",
    "\n",
    "export const speedPeak: SpeedPeakRow[] = [\n",
    "{rows_joined}\n",
    "];\n",
    "\"\"\"\n",
    "\n",
    "output_path = (\n",
    "    \"/Users/danielbrown/Desktop/mta-ace-buses/src/data/processed/speedOverall.ts\"\n",
    ")\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(ts)\n",
    "\n",
    "print(\"✅ speedOverall.ts written\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8649dc-5a3a-4404-a7aa-87b0a53ecbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "561545db-55ac-4742-a431-460e10e04980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom prophet import Prophet\\nimport pandas as pd\\nimport numpy as np\\n\\n# ------------------------------\\n# CONFIG\\n# ------------------------------\\nMIN_OBS = 12\\nUNCERTAINTY_SAMPLES = 1000\\nINTERVAL_WIDTH = 0.80   # 80% credible interval\\n\\n# ------------------------------\\n# Helper: summarize effect with uncertainty\\n# ------------------------------\\ndef summarize_effect(df_sub):\\n    if df_sub.empty:\\n        return {\\n            \"effect_pct\": np.nan,\\n            \"effect_pct_lower\": np.nan,\\n            \"effect_pct_upper\": np.nan,\\n            \"prob_positive\": np.nan\\n        }\\n\\n    y_mean = df_sub[\"y\"].mean()\\n\\n    yhat_mean = df_sub[\"yhat_no_policy\"].mean()\\n    yhat_lower = df_sub[\"yhat_no_policy_upper\"].mean()  # conservative\\n    yhat_upper = df_sub[\"yhat_no_policy_lower\"].mean()  # optimistic\\n\\n    effect_pct = ((y_mean - yhat_mean) / yhat_mean) * 100\\n    effect_pct_lower = ((y_mean - yhat_lower) / yhat_lower) * 100\\n    effect_pct_upper = ((y_mean - yhat_upper) / yhat_upper) * 100\\n\\n    prob_positive = (df_sub[\"y\"] > df_sub[\"yhat_no_policy\"]).mean()\\n\\n    return {\\n        \"effect_pct\": effect_pct,\\n        \"effect_pct_lower\": effect_pct_lower,\\n        \"effect_pct_upper\": effect_pct_upper,\\n        \"prob_positive\": prob_positive\\n    }\\n\\n# ------------------------------\\n# MAIN LOOP\\n# ------------------------------\\nresults = []\\n\\nfor route in df[\"route_id\"].unique():\\n\\n    # ------------------------------\\n    # Step 1: route data\\n    # ------------------------------\\n    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\\n\\n    if len(df_r) < MIN_OBS:\\n        continue\\n\\n    # ------------------------------\\n    # Step 2: regressors\\n    # ------------------------------\\n    df_r[\"is_able\"] = (\\n        df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])\\n    ).astype(int)\\n\\n    df_r[\"is_ace\"] = (\\n        df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])\\n    ).astype(int)\\n\\n    df_r[\"is_covid\"] = (\\n        (df_r[\"ds\"] >= \"2020-03-01\") &\\n        (df_r[\"ds\"] <= \"2020-09-01\")\\n    ).astype(int)\\n\\n    # ------------------------------\\n    # Step 3: fit Prophet\\n    # ------------------------------\\n    try:\\n        m = Prophet(\\n            yearly_seasonality=True,\\n            weekly_seasonality=False,\\n            daily_seasonality=False,\\n            uncertainty_samples=UNCERTAINTY_SAMPLES,\\n            interval_width=INTERVAL_WIDTH\\n        )\\n\\n        m.add_regressor(\"is_able\")\\n        m.add_regressor(\"is_ace\")\\n        m.add_regressor(\"is_covid\")\\n\\n        m.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\\n\\n    except Exception as e:\\n        print(f\"Skipping route {route}: {e}\")\\n        continue\\n\\n    # ------------------------------\\n    # Step 4: counterfactual forecast (no ABLE, no ACE)\\n    # ------------------------------\\n    future = df_r[[\"ds\", \"is_covid\"]].copy()\\n    future[\"is_able\"] = 0\\n    future[\"is_ace\"] = 0\\n\\n    forecast = m.predict(future)\\n\\n    df_r = df_r.merge(\\n        forecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]],\\n        on=\"ds\",\\n        how=\"left\"\\n    )\\n\\n    df_r.rename(\\n        columns={\\n            \"yhat\": \"yhat_no_policy\",\\n            \"yhat_lower\": \"yhat_no_policy_lower\",\\n            \"yhat_upper\": \"yhat_no_policy_upper\"\\n        },\\n        inplace=True\\n    )\\n\\n    # ------------------------------\\n    # Step 5: effect masks\\n    # ------------------------------\\n    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\\n    ace_mask = (df_r[\"is_ace\"] == 1)\\n\\n    # ------------------------------\\n    # Step 6: summarize effects\\n    # ------------------------------\\n    able_stats = summarize_effect(df_r.loc[able_only_mask])\\n    ace_stats = summarize_effect(df_r.loc[ace_mask])\\n\\n    # ------------------------------\\n    # Step 7: store results\\n    # ------------------------------\\n    results.append({\\n        \"route_id\": route,\\n\\n        \"able_effect_pct\": able_stats[\"effect_pct\"],\\n        \"able_effect_pct_lower\": able_stats[\"effect_pct_lower\"],\\n        \"able_effect_pct_upper\": able_stats[\"effect_pct_upper\"],\\n        \"able_prob_positive\": able_stats[\"prob_positive\"],\\n\\n        \"ace_incremental_effect_pct\": ace_stats[\"effect_pct\"],\\n        \"ace_effect_pct_lower\": ace_stats[\"effect_pct_lower\"],\\n        \"ace_effect_pct_upper\": ace_stats[\"effect_pct_upper\"],\\n        \"ace_prob_positive\": ace_stats[\"prob_positive\"]\\n    })\\n\\n# ------------------------------\\n# Step 8: final dataframe\\n# ------------------------------\\ndf_effects = pd.DataFrame(results)\\n\\ndf_effects\\n'"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------\n",
    "MIN_OBS = 12\n",
    "UNCERTAINTY_SAMPLES = 1000\n",
    "INTERVAL_WIDTH = 0.80   # 80% credible interval\n",
    "\n",
    "# ------------------------------\n",
    "# Helper: summarize effect with uncertainty\n",
    "# ------------------------------\n",
    "def summarize_effect(df_sub):\n",
    "    if df_sub.empty:\n",
    "        return {\n",
    "            \"effect_pct\": np.nan,\n",
    "            \"effect_pct_lower\": np.nan,\n",
    "            \"effect_pct_upper\": np.nan,\n",
    "            \"prob_positive\": np.nan\n",
    "        }\n",
    "\n",
    "    y_mean = df_sub[\"y\"].mean()\n",
    "\n",
    "    yhat_mean = df_sub[\"yhat_no_policy\"].mean()\n",
    "    yhat_lower = df_sub[\"yhat_no_policy_upper\"].mean()  # conservative\n",
    "    yhat_upper = df_sub[\"yhat_no_policy_lower\"].mean()  # optimistic\n",
    "\n",
    "    effect_pct = ((y_mean - yhat_mean) / yhat_mean) * 100\n",
    "    effect_pct_lower = ((y_mean - yhat_lower) / yhat_lower) * 100\n",
    "    effect_pct_upper = ((y_mean - yhat_upper) / yhat_upper) * 100\n",
    "\n",
    "    prob_positive = (df_sub[\"y\"] > df_sub[\"yhat_no_policy\"]).mean()\n",
    "\n",
    "    return {\n",
    "        \"effect_pct\": effect_pct,\n",
    "        \"effect_pct_lower\": effect_pct_lower,\n",
    "        \"effect_pct_upper\": effect_pct_upper,\n",
    "        \"prob_positive\": prob_positive\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN LOOP\n",
    "# ------------------------------\n",
    "results = []\n",
    "\n",
    "for route in df[\"route_id\"].unique():\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 1: route data\n",
    "    # ------------------------------\n",
    "    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\n",
    "\n",
    "    if len(df_r) < MIN_OBS:\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 2: regressors\n",
    "    # ------------------------------\n",
    "    df_r[\"is_able\"] = (\n",
    "        df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    df_r[\"is_ace\"] = (\n",
    "        df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    df_r[\"is_covid\"] = (\n",
    "        (df_r[\"ds\"] >= \"2020-03-01\") &\n",
    "        (df_r[\"ds\"] <= \"2020-09-01\")\n",
    "    ).astype(int)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 3: fit Prophet\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        m = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            uncertainty_samples=UNCERTAINTY_SAMPLES,\n",
    "            interval_width=INTERVAL_WIDTH\n",
    "        )\n",
    "\n",
    "        m.add_regressor(\"is_able\")\n",
    "        m.add_regressor(\"is_ace\")\n",
    "        m.add_regressor(\"is_covid\")\n",
    "\n",
    "        m.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping route {route}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 4: counterfactual forecast (no ABLE, no ACE)\n",
    "    # ------------------------------\n",
    "    future = df_r[[\"ds\", \"is_covid\"]].copy()\n",
    "    future[\"is_able\"] = 0\n",
    "    future[\"is_ace\"] = 0\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    df_r = df_r.merge(\n",
    "        forecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]],\n",
    "        on=\"ds\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df_r.rename(\n",
    "        columns={\n",
    "            \"yhat\": \"yhat_no_policy\",\n",
    "            \"yhat_lower\": \"yhat_no_policy_lower\",\n",
    "            \"yhat_upper\": \"yhat_no_policy_upper\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 5: effect masks\n",
    "    # ------------------------------\n",
    "    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\n",
    "    ace_mask = (df_r[\"is_ace\"] == 1)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 6: summarize effects\n",
    "    # ------------------------------\n",
    "    able_stats = summarize_effect(df_r.loc[able_only_mask])\n",
    "    ace_stats = summarize_effect(df_r.loc[ace_mask])\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 7: store results\n",
    "    # ------------------------------\n",
    "    results.append({\n",
    "        \"route_id\": route,\n",
    "\n",
    "        \"able_effect_pct\": able_stats[\"effect_pct\"],\n",
    "        \"able_effect_pct_lower\": able_stats[\"effect_pct_lower\"],\n",
    "        \"able_effect_pct_upper\": able_stats[\"effect_pct_upper\"],\n",
    "        \"able_prob_positive\": able_stats[\"prob_positive\"],\n",
    "\n",
    "        \"ace_incremental_effect_pct\": ace_stats[\"effect_pct\"],\n",
    "        \"ace_effect_pct_lower\": ace_stats[\"effect_pct_lower\"],\n",
    "        \"ace_effect_pct_upper\": ace_stats[\"effect_pct_upper\"],\n",
    "        \"ace_prob_positive\": ace_stats[\"prob_positive\"]\n",
    "    })\n",
    "\n",
    "# ------------------------------\n",
    "# Step 8: final dataframe\n",
    "# ------------------------------\n",
    "df_effects = pd.DataFrame(results)\n",
    "\n",
    "df_effects\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "cc8ade7e-e245-4585-8674-80aab5314902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport numpy as np\\nfrom scipy.stats import skew, kurtosis\\n\\n# ------------------------------\\n# Columns to summarize\\n# ------------------------------\\neffect_cols = [\\n    \"able_effect_pct\", \"able_effect_pct_lower\", \"able_effect_pct_upper\", \"able_prob_positive\",\\n    \"ace_incremental_effect_pct\", \"ace_effect_pct_lower\", \"ace_effect_pct_upper\", \"ace_prob_positive\"\\n]\\n\\n# ------------------------------\\n# Prepare summary dictionary\\n# ------------------------------\\nsummary_stats = {}\\n\\nfor col in effect_cols:\\n    data = df_effects[col].dropna()\\n    n = len(data)\\n    \\n    if n == 0:\\n        summary_stats[col] = {k: np.nan for k in [\\n            \"count\",\"mean\",\"median\",\"std\",\"min\",\"q25\",\"q75\",\"max\",\"iqr\",\"skew\",\"kurtosis\",\"frac_positive\",\"frac_ci_positive\"\\n        ]}\\n        continue\\n    \\n    # Determine if this is an \"effect\" column (vs probability)\\n    is_effect = \"effect\" in col and \"prob\" not in col\\n    is_lower_bound = \"_lower\" in col\\n    \\n    summary_stats[col] = {\\n        \"count\": n,\\n        \"mean\": data.mean(),\\n        \"median\": data.median(),\\n        \"std\": data.std(),\\n        \"min\": data.min(),\\n        \"q25\": np.percentile(data, 25),\\n        \"q75\": np.percentile(data, 75),\\n        \"iqr\": np.percentile(data, 75) - np.percentile(data, 25),\\n        \"max\": data.max(),\\n        \"skew\": skew(data),\\n        \"kurtosis\": kurtosis(data),\\n        \"frac_positive\": (data > 0).mean() if is_effect else np.nan,\\n        \"frac_ci_positive\": (data > 0).mean() if is_lower_bound else np.nan\\n    }\\n\\n# ------------------------------\\n# Convert to DataFrame for display\\n# ------------------------------\\nsummary_df = pd.DataFrame(summary_stats).T\\nsummary_df\\n'"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# ------------------------------\n",
    "# Columns to summarize\n",
    "# ------------------------------\n",
    "effect_cols = [\n",
    "    \"able_effect_pct\", \"able_effect_pct_lower\", \"able_effect_pct_upper\", \"able_prob_positive\",\n",
    "    \"ace_incremental_effect_pct\", \"ace_effect_pct_lower\", \"ace_effect_pct_upper\", \"ace_prob_positive\"\n",
    "]\n",
    "\n",
    "# ------------------------------\n",
    "# Prepare summary dictionary\n",
    "# ------------------------------\n",
    "summary_stats = {}\n",
    "\n",
    "for col in effect_cols:\n",
    "    data = df_effects[col].dropna()\n",
    "    n = len(data)\n",
    "    \n",
    "    if n == 0:\n",
    "        summary_stats[col] = {k: np.nan for k in [\n",
    "            \"count\",\"mean\",\"median\",\"std\",\"min\",\"q25\",\"q75\",\"max\",\"iqr\",\"skew\",\"kurtosis\",\"frac_positive\",\"frac_ci_positive\"\n",
    "        ]}\n",
    "        continue\n",
    "    \n",
    "    # Determine if this is an \"effect\" column (vs probability)\n",
    "    is_effect = \"effect\" in col and \"prob\" not in col\n",
    "    is_lower_bound = \"_lower\" in col\n",
    "    \n",
    "    summary_stats[col] = {\n",
    "        \"count\": n,\n",
    "        \"mean\": data.mean(),\n",
    "        \"median\": data.median(),\n",
    "        \"std\": data.std(),\n",
    "        \"min\": data.min(),\n",
    "        \"q25\": np.percentile(data, 25),\n",
    "        \"q75\": np.percentile(data, 75),\n",
    "        \"iqr\": np.percentile(data, 75) - np.percentile(data, 25),\n",
    "        \"max\": data.max(),\n",
    "        \"skew\": skew(data),\n",
    "        \"kurtosis\": kurtosis(data),\n",
    "        \"frac_positive\": (data > 0).mean() if is_effect else np.nan,\n",
    "        \"frac_ci_positive\": (data > 0).mean() if is_lower_bound else np.nan\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Convert to DataFrame for display\n",
    "# ------------------------------\n",
    "summary_df = pd.DataFrame(summary_stats).T\n",
    "summary_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a522c-c213-467f-bbe3-8806a07db08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "709eca27-e086-4ba2-8750-999f8c9971d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom prophet import Prophet\\nimport pandas as pd\\nimport numpy as np\\n\\n# ------------------------------\\n# CONFIG\\n# ------------------------------\\nMIN_OBS = 12\\nUNCERTAINTY_SAMPLES = 1000\\nINTERVAL_WIDTH = 0.80\\nEPS = 1e-6\\n\\n# ------------------------------\\n# Utility functions\\n# ------------------------------\\ndef pct_effect(y_obs, y_cf):\\n    \"\"\"Safe percent effect calculation.\"\"\"\\n    y_cf = max(y_cf, EPS)\\n    return (y_obs - y_cf) / y_cf * 100\\n\\n\\ndef summarize_effect(df_sub):\\n    \"\"\"Summarize average effect with uncertainty.\"\"\"\\n    if df_sub.empty:\\n        return {\\n            \"effect_pct\": np.nan,\\n            \"effect_pct_lower\": np.nan,\\n            \"effect_pct_upper\": np.nan,\\n            \"prob_positive\": np.nan\\n        }\\n\\n    y_mean = df_sub[\"y\"].mean()\\n\\n    yhat_mean = df_sub[\"yhat_no_policy\"].mean()\\n    yhat_cf_high = df_sub[\"yhat_no_policy_upper\"].mean()  # conservative\\n    yhat_cf_low = df_sub[\"yhat_no_policy_lower\"].mean()   # optimistic\\n\\n    effect_pct = pct_effect(y_mean, yhat_mean)\\n    effect_pct_lower = pct_effect(y_mean, yhat_cf_high)\\n    effect_pct_upper = pct_effect(y_mean, yhat_cf_low)\\n\\n    prob_positive = (df_sub[\"y\"] > df_sub[\"yhat_no_policy\"]).mean()\\n\\n    return {\\n        \"effect_pct\": effect_pct,\\n        \"effect_pct_lower\": effect_pct_lower,\\n        \"effect_pct_upper\": effect_pct_upper,\\n        \"prob_positive\": prob_positive\\n    }\\n\\n\\ndef combine_effects(a, b):\\n    \"\"\"Combine two percent effects multiplicatively.\"\"\"\\n    if np.isnan(a) and np.isnan(b):\\n        return np.nan\\n    a = 0 if np.isnan(a) else a\\n    b = 0 if np.isnan(b) else b\\n    return ((1 + a / 100) * (1 + b / 100) - 1) * 100\\n\\n\\n# ------------------------------\\n# MAIN LOOP\\n# ------------------------------\\nresults = []\\n\\nfor route in df[\"route_id\"].unique():\\n\\n    # ------------------------------\\n    # Step 1: route data\\n    # ------------------------------\\n    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\\n\\n    if len(df_r) < MIN_OBS:\\n        continue\\n\\n    # ------------------------------\\n    # Step 2: regressors\\n    # ------------------------------\\n    df_r[\"is_able\"] = (\\n        df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])\\n    ).astype(int)\\n\\n    df_r[\"is_ace\"] = (\\n        df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])\\n    ).astype(int)\\n\\n    df_r[\"is_covid\"] = (\\n        (df_r[\"ds\"] >= \"2020-03-01\") &\\n        (df_r[\"ds\"] <= \"2020-09-01\")\\n    ).astype(int)\\n\\n    # ------------------------------\\n    # Step 3: fit Prophet\\n    # ------------------------------\\n    try:\\n        m = Prophet(\\n            yearly_seasonality=True,\\n            weekly_seasonality=False,\\n            daily_seasonality=False,\\n            uncertainty_samples=UNCERTAINTY_SAMPLES,\\n            interval_width=INTERVAL_WIDTH\\n        )\\n\\n        m.add_regressor(\"is_able\")\\n        m.add_regressor(\"is_ace\")\\n        m.add_regressor(\"is_covid\")\\n\\n        m.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\\n\\n    except Exception as e:\\n        print(f\"Skipping route {route}: {e}\")\\n        continue\\n\\n    # ------------------------------\\n    # Step 4: counterfactual forecast (no ABLE, no ACE)\\n    # ------------------------------\\n    future = df_r[[\"ds\", \"is_covid\"]].copy()\\n    future[\"is_able\"] = 0\\n    future[\"is_ace\"] = 0\\n\\n    forecast = m.predict(future)\\n\\n    df_r = df_r.merge(\\n        forecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]],\\n        on=\"ds\",\\n        how=\"left\"\\n    )\\n\\n    df_r.rename(\\n        columns={\\n            \"yhat\": \"yhat_no_policy\",\\n            \"yhat_lower\": \"yhat_no_policy_lower\",\\n            \"yhat_upper\": \"yhat_no_policy_upper\"\\n        },\\n        inplace=True\\n    )\\n\\n    # ------------------------------\\n    # Step 5: effect masks\\n    # ------------------------------\\n    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\\n    ace_mask = (df_r[\"is_ace\"] == 1)\\n\\n    # ------------------------------\\n    # Step 6: summarize effects\\n    # ------------------------------\\n    able_stats = summarize_effect(df_r.loc[able_only_mask])\\n    ace_stats = summarize_effect(df_r.loc[ace_mask])\\n\\n    # ------------------------------\\n    # Step 7: store results\\n    # ------------------------------\\n    results.append({\\n        \"route_id\": route,\\n\\n        \"able_effect_pct\": able_stats[\"effect_pct\"],\\n        \"able_effect_pct_lower\": able_stats[\"effect_pct_lower\"],\\n        \"able_effect_pct_upper\": able_stats[\"effect_pct_upper\"],\\n        \"able_prob_positive\": able_stats[\"prob_positive\"],\\n\\n        \"ace_incremental_effect_pct\": ace_stats[\"effect_pct\"],\\n        \"ace_effect_pct_lower\": ace_stats[\"effect_pct_lower\"],\\n        \"ace_effect_pct_upper\": ace_stats[\"effect_pct_upper\"],\\n        \"ace_prob_positive\": ace_stats[\"prob_positive\"],\\n    })\\n\\n# ------------------------------\\n# Step 8: final dataframe\\n# ------------------------------\\ndf_effects = pd.DataFrame(results)\\n\\n# ------------------------------\\n# Step 9: total effects (point + uncertainty)\\n# ------------------------------\\ndf_effects[\"total_effect_pct\"] = df_effects.apply(\\n    lambda r: combine_effects(\\n        r[\"able_effect_pct\"],\\n        r[\"ace_incremental_effect_pct\"]\\n    ),\\n    axis=1\\n)\\n\\ndf_effects[\"total_effect_pct_lower\"] = df_effects.apply(\\n    lambda r: combine_effects(\\n        r[\"able_effect_pct_lower\"],\\n        r[\"ace_effect_pct_lower\"]\\n    ),\\n    axis=1\\n)\\n\\ndf_effects[\"total_effect_pct_upper\"] = df_effects.apply(\\n    lambda r: combine_effects(\\n        r[\"able_effect_pct_upper\"],\\n        r[\"ace_effect_pct_upper\"]\\n    ),\\n    axis=1\\n)\\n\\n# Probability total effect is positive (union)\\ndf_effects[\"total_prob_positive\"] = (\\n    1\\n    - (1 - df_effects[\"able_prob_positive\"].fillna(0))\\n    * (1 - df_effects[\"ace_prob_positive\"].fillna(0))\\n)\\n\\ndf_effects\\n'"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will be used for individual routes, when we look at them\n",
    "'''\n",
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------\n",
    "MIN_OBS = 12\n",
    "UNCERTAINTY_SAMPLES = 1000\n",
    "INTERVAL_WIDTH = 0.80\n",
    "EPS = 1e-6\n",
    "\n",
    "# ------------------------------\n",
    "# Utility functions\n",
    "# ------------------------------\n",
    "def pct_effect(y_obs, y_cf):\n",
    "    \"\"\"Safe percent effect calculation.\"\"\"\n",
    "    y_cf = max(y_cf, EPS)\n",
    "    return (y_obs - y_cf) / y_cf * 100\n",
    "\n",
    "\n",
    "def summarize_effect(df_sub):\n",
    "    \"\"\"Summarize average effect with uncertainty.\"\"\"\n",
    "    if df_sub.empty:\n",
    "        return {\n",
    "            \"effect_pct\": np.nan,\n",
    "            \"effect_pct_lower\": np.nan,\n",
    "            \"effect_pct_upper\": np.nan,\n",
    "            \"prob_positive\": np.nan\n",
    "        }\n",
    "\n",
    "    y_mean = df_sub[\"y\"].mean()\n",
    "\n",
    "    yhat_mean = df_sub[\"yhat_no_policy\"].mean()\n",
    "    yhat_cf_high = df_sub[\"yhat_no_policy_upper\"].mean()  # conservative\n",
    "    yhat_cf_low = df_sub[\"yhat_no_policy_lower\"].mean()   # optimistic\n",
    "\n",
    "    effect_pct = pct_effect(y_mean, yhat_mean)\n",
    "    effect_pct_lower = pct_effect(y_mean, yhat_cf_high)\n",
    "    effect_pct_upper = pct_effect(y_mean, yhat_cf_low)\n",
    "\n",
    "    prob_positive = (df_sub[\"y\"] > df_sub[\"yhat_no_policy\"]).mean()\n",
    "\n",
    "    return {\n",
    "        \"effect_pct\": effect_pct,\n",
    "        \"effect_pct_lower\": effect_pct_lower,\n",
    "        \"effect_pct_upper\": effect_pct_upper,\n",
    "        \"prob_positive\": prob_positive\n",
    "    }\n",
    "\n",
    "\n",
    "def combine_effects(a, b):\n",
    "    \"\"\"Combine two percent effects multiplicatively.\"\"\"\n",
    "    if np.isnan(a) and np.isnan(b):\n",
    "        return np.nan\n",
    "    a = 0 if np.isnan(a) else a\n",
    "    b = 0 if np.isnan(b) else b\n",
    "    return ((1 + a / 100) * (1 + b / 100) - 1) * 100\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN LOOP\n",
    "# ------------------------------\n",
    "results = []\n",
    "\n",
    "for route in df[\"route_id\"].unique():\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 1: route data\n",
    "    # ------------------------------\n",
    "    df_r = df[df[\"route_id\"] == route].sort_values(\"ds\").copy()\n",
    "\n",
    "    if len(df_r) < MIN_OBS:\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 2: regressors\n",
    "    # ------------------------------\n",
    "    df_r[\"is_able\"] = (\n",
    "        df_r[\"ABLE\"].notna() & (df_r[\"ds\"] >= df_r[\"ABLE\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    df_r[\"is_ace\"] = (\n",
    "        df_r[\"ACE\"].notna() & (df_r[\"ds\"] >= df_r[\"ACE\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    df_r[\"is_covid\"] = (\n",
    "        (df_r[\"ds\"] >= \"2020-03-01\") &\n",
    "        (df_r[\"ds\"] <= \"2020-09-01\")\n",
    "    ).astype(int)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 3: fit Prophet\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        m = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            uncertainty_samples=UNCERTAINTY_SAMPLES,\n",
    "            interval_width=INTERVAL_WIDTH\n",
    "        )\n",
    "\n",
    "        m.add_regressor(\"is_able\")\n",
    "        m.add_regressor(\"is_ace\")\n",
    "        m.add_regressor(\"is_covid\")\n",
    "\n",
    "        m.fit(df_r[[\"ds\", \"y\", \"is_able\", \"is_ace\", \"is_covid\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping route {route}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 4: counterfactual forecast (no ABLE, no ACE)\n",
    "    # ------------------------------\n",
    "    future = df_r[[\"ds\", \"is_covid\"]].copy()\n",
    "    future[\"is_able\"] = 0\n",
    "    future[\"is_ace\"] = 0\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    df_r = df_r.merge(\n",
    "        forecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]],\n",
    "        on=\"ds\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df_r.rename(\n",
    "        columns={\n",
    "            \"yhat\": \"yhat_no_policy\",\n",
    "            \"yhat_lower\": \"yhat_no_policy_lower\",\n",
    "            \"yhat_upper\": \"yhat_no_policy_upper\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 5: effect masks\n",
    "    # ------------------------------\n",
    "    able_only_mask = (df_r[\"is_able\"] == 1) & (df_r[\"is_ace\"] == 0)\n",
    "    ace_mask = (df_r[\"is_ace\"] == 1)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 6: summarize effects\n",
    "    # ------------------------------\n",
    "    able_stats = summarize_effect(df_r.loc[able_only_mask])\n",
    "    ace_stats = summarize_effect(df_r.loc[ace_mask])\n",
    "\n",
    "    # ------------------------------\n",
    "    # Step 7: store results\n",
    "    # ------------------------------\n",
    "    results.append({\n",
    "        \"route_id\": route,\n",
    "\n",
    "        \"able_effect_pct\": able_stats[\"effect_pct\"],\n",
    "        \"able_effect_pct_lower\": able_stats[\"effect_pct_lower\"],\n",
    "        \"able_effect_pct_upper\": able_stats[\"effect_pct_upper\"],\n",
    "        \"able_prob_positive\": able_stats[\"prob_positive\"],\n",
    "\n",
    "        \"ace_incremental_effect_pct\": ace_stats[\"effect_pct\"],\n",
    "        \"ace_effect_pct_lower\": ace_stats[\"effect_pct_lower\"],\n",
    "        \"ace_effect_pct_upper\": ace_stats[\"effect_pct_upper\"],\n",
    "        \"ace_prob_positive\": ace_stats[\"prob_positive\"],\n",
    "    })\n",
    "\n",
    "# ------------------------------\n",
    "# Step 8: final dataframe\n",
    "# ------------------------------\n",
    "df_effects = pd.DataFrame(results)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 9: total effects (point + uncertainty)\n",
    "# ------------------------------\n",
    "df_effects[\"total_effect_pct\"] = df_effects.apply(\n",
    "    lambda r: combine_effects(\n",
    "        r[\"able_effect_pct\"],\n",
    "        r[\"ace_incremental_effect_pct\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_effects[\"total_effect_pct_lower\"] = df_effects.apply(\n",
    "    lambda r: combine_effects(\n",
    "        r[\"able_effect_pct_lower\"],\n",
    "        r[\"ace_effect_pct_lower\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_effects[\"total_effect_pct_upper\"] = df_effects.apply(\n",
    "    lambda r: combine_effects(\n",
    "        r[\"able_effect_pct_upper\"],\n",
    "        r[\"ace_effect_pct_upper\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Probability total effect is positive (union)\n",
    "df_effects[\"total_prob_positive\"] = (\n",
    "    1\n",
    "    - (1 - df_effects[\"able_prob_positive\"].fillna(0))\n",
    "    * (1 - df_effects[\"ace_prob_positive\"].fillna(0))\n",
    ")\n",
    "\n",
    "df_effects\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "1d84f682-eabd-4804-9433-ba1d504f57e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_curve = (\\n    df_effects\\n    .sort_values(\"total_prob_positive\", ascending=False)\\n    .reset_index(drop=True)\\n)\\n\\ndf_curve[\"cum_share\"] = (df_curve.index + 1) / len(df_curve)\\n'"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_curve = (\n",
    "    df_effects\n",
    "    .sort_values(\"total_prob_positive\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_curve[\"cum_share\"] = (df_curve.index + 1) / len(df_curve)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "d465a3e4-e9e7-47ff-aa4b-2d5d16c4826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(7, 5))\\n\\nplt.plot(\\n    df_curve[\"total_prob_positive\"],\\n    df_curve[\"cum_share\"],\\n    marker=\"o\",\\n    linewidth=2\\n)\\n\\n# Reference lines\\nplt.axvline(0.8, linestyle=\"--\", color=\"gray\", alpha=0.7)\\nplt.axhline(0.5, linestyle=\"--\", color=\"gray\", alpha=0.7)\\n\\nplt.xlim(0, 1)\\nplt.ylim(0, 1)\\n\\nplt.xlabel(\"Confidence threshold (P[effect > 0])\")\\nplt.ylabel(\"Cumulative share of routes\")\\nplt.title(\"Cumulative success curve for ABLE + ACE program\")\\n\\nplt.grid(True, alpha=0.3)\\nplt.tight_layout()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(\n",
    "    df_curve[\"total_prob_positive\"],\n",
    "    df_curve[\"cum_share\"],\n",
    "    marker=\"o\",\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Reference lines\n",
    "plt.axvline(0.8, linestyle=\"--\", color=\"gray\", alpha=0.7)\n",
    "plt.axhline(0.5, linestyle=\"--\", color=\"gray\", alpha=0.7)\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(\"Confidence threshold (P[effect > 0])\")\n",
    "plt.ylabel(\"Cumulative share of routes\")\n",
    "plt.title(\"Cumulative success curve for ABLE + ACE program\")\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "0466b731-103e-469a-84b7-0a4e278bccef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\ndf_bar = df_effects.copy()\\ndf_bar[\"outcome\"] = pd.cut(\\n    df_bar[\"total_prob_positive\"],\\n    bins=[0, 0.2, 0.8, 1.0],\\n    labels=[\"Likely negative\", \"Uncertain\", \"Likely positive\"],\\n    include_lowest=True\\n)\\n\\nshare = df_bar[\"outcome\"].value_counts(normalize=True).reindex([\"Likely negative\", \"Uncertain\", \"Likely positive\"])\\n\\nplt.figure(figsize=(6, 2))\\nplt.barh(\\n    [\"ABLE + ACE\"],\\n    share[\"Likely negative\"],\\n    color=\"#d73027\",\\n    label=\"Likely negative\"\\n)\\nplt.barh(\\n    [\"ABLE + ACE\"],\\n    share[\"Uncertain\"],\\n    left=share[\"Likely negative\"],\\n    color=\"#fdae61\",\\n    label=\"Uncertain\"\\n)\\nplt.barh(\\n    [\"ABLE + ACE\"],\\n    share[\"Likely positive\"],\\n    left=share[\"Likely negative\"] + share[\"Uncertain\"],\\n    color=\"#1a9850\",\\n    label=\"Likely positive\"\\n)\\nplt.xlim(0, 1)\\nplt.xlabel(\"Share of routes\")\\nplt.title(\"Overall program impact across routes\")\\nplt.legend(loc=\\'center left\\', bbox_to_anchor=(1,0.5))\\nplt.show()\\n'"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_bar = df_effects.copy()\n",
    "df_bar[\"outcome\"] = pd.cut(\n",
    "    df_bar[\"total_prob_positive\"],\n",
    "    bins=[0, 0.2, 0.8, 1.0],\n",
    "    labels=[\"Likely negative\", \"Uncertain\", \"Likely positive\"],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "share = df_bar[\"outcome\"].value_counts(normalize=True).reindex([\"Likely negative\", \"Uncertain\", \"Likely positive\"])\n",
    "\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.barh(\n",
    "    [\"ABLE + ACE\"],\n",
    "    share[\"Likely negative\"],\n",
    "    color=\"#d73027\",\n",
    "    label=\"Likely negative\"\n",
    ")\n",
    "plt.barh(\n",
    "    [\"ABLE + ACE\"],\n",
    "    share[\"Uncertain\"],\n",
    "    left=share[\"Likely negative\"],\n",
    "    color=\"#fdae61\",\n",
    "    label=\"Uncertain\"\n",
    ")\n",
    "plt.barh(\n",
    "    [\"ABLE + ACE\"],\n",
    "    share[\"Likely positive\"],\n",
    "    left=share[\"Likely negative\"] + share[\"Uncertain\"],\n",
    "    color=\"#1a9850\",\n",
    "    label=\"Likely positive\"\n",
    ")\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Share of routes\")\n",
    "plt.title(\"Overall program impact across routes\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24058b7d-084a-4a99-a6dd-4c6134dae7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1c950-ad34-4863-a6e1-f7c1d441edc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192a145-5e84-45e8-9027-955fe6febe82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a496c-ab39-4d1c-8fba-b1cbb5ba189f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0727d5-e62b-45f0-b4a5-031555fbba93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clean_env)",
   "language": "python",
   "name": "my_clean_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
